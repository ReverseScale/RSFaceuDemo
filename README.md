# RSFaceuDemo

![](https://img.shields.io/badge/platform-iOS-red.svg) 
![](https://img.shields.io/badge/language-Objective--C-orange.svg) 
![](https://img.shields.io/badge/download-11.6MB-brightgreen.svg) 
![](https://img.shields.io/badge/license-MIT%20License-brightgreen.svg) 

[EN](#Requirements) | [ä¸­æ–‡](#ä¸­æ–‡è¯´æ˜)

Faceu Face Moe must have had a set of its own core algorithms, so it would say "Someone mimics my face ..."

Recently in the study of some image processing technology, the most common applications are the number of "Faceu Meng", in order to show clearer, I choose to split the way to achieve Demo.

## ğŸ¨ Why test the UI?

|1.List page | 2.Filter effect page | 3.Green screen image page | 4.Static composition page |
| ------------- | ------------- | ------------- | ------------- |
| ![](http://og1yl0w9z.bkt.clouddn.com/18-3-14/35442700.jpg) | ![](http://og1yl0w9z.bkt.clouddn.com/18-3-14/79019240.jpg) | ![](http://og1yl0w9z.bkt.clouddn.com/18-3-14/56773520.jpg) | ![](http://og1yl0w9z.bkt.clouddn.com/18-3-14/86588720.jpg) |
| Build a basic framework | Several filter effects | Realize green screen artifacts | Static synthesis Gif |

## ğŸš€ Advantage 
* 1. Less documents, code concise, innovative features
* 2. High functionality integration, good experience, fine structure
* 3. Relies solely on GPUImage to achieve
* 4. Has a high custom

## ğŸ¤– Requirements 
* iOS 7+
* Xcode 8+


## ğŸ›  Usage
### filter effect
Core code display:

```
//Convert UIImage to CIImage
CIImage *ciImage = [[CIImage alloc] initWithImage:self.originImage];
//Create a filter
CIFilter *filter = [CIFilter filterWithName:filterName
                              keysAndValues:kCIInputImageKey,ciImage, nil];
//The existing value does not change, the other is set as the default value
[filter setDefaults];
        
//Get the drawing context
CIContext *context = [CIContext contextWithOptions:nil];
        
//Render and output CIImage
CIImage *outputImage = [filter outputImage];
        
//Create a CGImage handle
CGImageRef cgImage = [context createCGImage:outputImage fromRect:[outputImage extent]];
        
//Get the picture
UIImage *image = [UIImage imageWithCGImage:cgImage];
        
//Release the CGImage handle
CGImageRelease(cgImage);
        
self.imageView.image = image;
```

### green screen keying

Quote header file:
```
#import "RSChromaKeyFilter.h"
```

Tool method:

```
RSChromaKeyFilter *filter=[[RSChromaKeyFilter alloc] initWithInputImage:self.greenImageView.image
                                                        backgroundImage:self.resultBgImageView.image];
    
self.resultImageView.image=[[UIImage imageWithCIImage:filter.outputImage] copy];
```

### Static Synthesis

Effect demonstration:

![](http://og1yl0w9z.bkt.clouddn.com/17-9-4/17807305.jpg) 

Quote header file:

```
#import <CoreImage/CoreImage.h>
#import "UIImageView+Gif.h"
```

The core method:

```
// Image Recognition: You can choose between CIDetectorAccuracyHigh and CIDetectorAccuracyLow, because you want to be more accurate
CIDetectorAccuracyHigh
NSDictionary *opts = [NSDictionary dictionaryWithObject:CIDetectorAccuracyHigh
                                                 forKey:CIDetectorAccuracy];

CIDetector *detector=[CIDetector detectorOfType:CIDetectorTypeFace context:nil options:opts];
CIImage *image=[[CIImage alloc] initWithImage:self.oldImageView.image];
NSArray *faceArray = [detector featuresInImage:image
                                       options:nil];

/ ** Convert Core Image Coordinates to UIView Coordinates ** /
// get the size of the image
CGSize ciImageSize = [image extent] .size ;;
// Symmetry the image along the y axis
CGAffineTransform transform = CGAffineTransformScale(CGAffineTransformIdentity, 1, -1);
// Negative y-axis translation
transform = CGAffineTransformTranslate(transform,0,-ciImageSize.height);

for (CIFeature *f in faceArray){
    
    if ([f.type isEqualToString:CIFeatureTypeFace]) {
        
        CIFaceFeature *faceFeature=(CIFaceFeature *)f;
        // Achieve coordinate conversion
        CGSize viewSize = self.oldImageView.bounds.size;
        CGFloat scale = MIN(viewSize.width / ciImageSize.width,
                            viewSize.height / ciImageSize.height);
        CGFloat offsetX = (viewSize.width - ciImageSize.width * scale) / 2;
        CGFloat offsetY = (viewSize.height - ciImageSize.height * scale) / 2;
        // Zoom
        CGAffineTransform scaleTransform = CGAffineTransformMakeScale(scale, scale);
        // Get face frame
        CGRect faceViewBounds = CGRectApplyAffineTransform(faceFeature.bounds, transform);
        // Fix
        faceViewBounds = CGRectApplyAffineTransform(faceViewBounds,scaleTransform);
        faceViewBounds.origin.x += offsetX;
        faceViewBounds.origin.y += offsetY;
        
        UIView *faceView=[[UIView alloc] initWithFrame:faceViewBounds];
        faceView.layer.borderWidth=3;
        faceView.layer.borderColor=[UIColor orangeColor].CGColor;
        
        [self.oldImageView addSubview:faceView];
        
        / ** plus light ring ** /
        UIImageView *imageView=[UIImageView new];
        CGFloat haloWidth= faceViewBounds.size.width;
        CGFloat haloHeight= haloWidth * 159 / 351;
        
        ...
    }
}
```

### Dynamic synthesis

Effect demonstration:

![](http://og1yl0w9z.bkt.clouddn.com/17-9-4/28926041.jpg) 

Quote header file:
```
#import <GPUImage/GPUImage.h>
```

The core method:
```
_faceThinking = YES;
CVPixelBufferRef pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer);
CFDictionaryRef attachments = CMCopyDictionaryOfAttachments(kCFAllocatorDefault, sampleBuffer, kCMAttachmentMode_ShouldPropagate);
CIImage *convertedImage = [[CIImage alloc] initWithCVPixelBuffer:pixelBuffer options:(__bridge NSDictionary *)attachments];

if (attachments)
    CFRelease(attachments);
NSDictionary *imageOptions = nil;
UIDeviceOrientation curDeviceOrientation = [[UIDevice currentDevice] orientation];
int exifOrientation;

enum {
    PHOTOS_EXIF_0ROW_TOP_0COL_LEFT			= 1, //   1  =  0th row is at the top, and 0th column is on the left (THE DEFAULT).
    PHOTOS_EXIF_0ROW_TOP_0COL_RIGHT			= 2, //   2  =  0th row is at the top, and 0th column is on the right.
    PHOTOS_EXIF_0ROW_BOTTOM_0COL_RIGHT      = 3, //   3  =  0th row is at the bottom, and 0th column is on the right.
    PHOTOS_EXIF_0ROW_BOTTOM_0COL_LEFT       = 4, //   4  =  0th row is at the bottom, and 0th column is on the left.
    PHOTOS_EXIF_0ROW_LEFT_0COL_TOP          = 5, //   5  =  0th row is on the left, and 0th column is the top.
    PHOTOS_EXIF_0ROW_RIGHT_0COL_TOP         = 6, //   6  =  0th row is on the right, and 0th column is the top.
    PHOTOS_EXIF_0ROW_RIGHT_0COL_BOTTOM      = 7, //   7  =  0th row is on the right, and 0th column is the bottom.
    PHOTOS_EXIF_0ROW_LEFT_0COL_BOTTOM       = 8  //   8  =  0th row is on the left, and 0th column is the bottom.
};
BOOL isUsingFrontFacingCamera = FALSE;
AVCaptureDevicePosition currentCameraPosition = [self.videoCamera cameraPosition];

...
```


## âš– License

```
MIT License

Copyright (c) 2017 ReverseScale

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

## ğŸ˜¬ Contributions

* WeChat : WhatsXie
* Email : ReverseScale@iCloud.com
* Blog : https://reversescale.github.io

---
# ä¸­æ–‡è¯´æ˜

Faceuè„¸èŒä¸€å®šæ˜¯æœ‰ä¸€å¥—è‡ªå·±çš„æ ¸å¿ƒç®—æ³•ï¼Œæ‰€ä»¥å®ƒä¼šè¯´â€œæœ‰äººæ¨¡ä»¿æˆ‘çš„è„¸...â€

æœ€è¿‘åœ¨ç ”ç©¶ä¸€äº›å›¾åƒå¤„ç†çš„æŠ€æœ¯ï¼Œå…¶ä¸­æœ€å¸¸è§çš„åº”ç”¨å°±è¦æ•° â€œFaceu è„¸èŒâ€ äº†ï¼Œä¸ºäº†å±•ç¤ºæ›´æ¸…æ™°ï¼Œæˆ‘é€‰æ‹©æ‹†åˆ†åŠŸèƒ½çš„æ–¹å¼æ¥å®ç° Demoã€‚

## ğŸ¨ æµ‹è¯• UI ä»€ä¹ˆæ ·å­ï¼Ÿ

|1.åˆ—è¡¨é¡µ |2.æ»¤é•œæ•ˆæœé¡µ |3.ç»¿å±æŠ åƒé¡µ |4.é™æ€åˆæˆé¡µ |
| ------------- | ------------- | ------------- | ------------- |
| ![](http://og1yl0w9z.bkt.clouddn.com/18-3-14/35442700.jpg) | ![](http://og1yl0w9z.bkt.clouddn.com/18-3-14/79019240.jpg) | ![](http://og1yl0w9z.bkt.clouddn.com/18-3-14/56773520.jpg) | ![](http://og1yl0w9z.bkt.clouddn.com/18-3-14/86588720.jpg) |
| æ­å»ºåŸºæœ¬æ¡†æ¶ | å‡ ç§æ»¤é•œæ•ˆæœ | å®ç°ç»¿å±æŠ åƒ | é™æ€åˆæˆGif |


## ğŸš€ æ¡†æ¶çš„ä¼˜åŠ¿
* 1.æ–‡ä»¶å°‘ï¼Œä»£ç ç®€æ´ï¼ŒåŠŸèƒ½æ–°é¢–
* 2.åŠŸèƒ½æ•´åˆåº¦é«˜ï¼Œä½“éªŒå¥½ï¼Œç»“æ„ç²¾
* 3.å•çº¯ä¾èµ– GPUImage æ¥å®ç°
* 4.å…·å¤‡è¾ƒé«˜è‡ªå®šä¹‰æ€§

## ğŸ¤– è¦æ±‚
* iOS 7+
* Xcode 8+

## ğŸ›  ä½¿ç”¨æ–¹æ³•
### æ»¤é•œæ•ˆæœ 
æ ¸å¿ƒä»£ç å±•ç¤ºï¼š

```
//å°†UIImageè½¬æ¢æˆCIImage
CIImage *ciImage = [[CIImage alloc] initWithImage:self.originImage];
//åˆ›å»ºæ»¤é•œ
CIFilter *filter = [CIFilter filterWithName:filterName
                              keysAndValues:kCIInputImageKey,ciImage, nil];
//å·²æœ‰çš„å€¼ä¸æ”¹å˜ï¼Œå…¶ä»–çš„è®¾ä¸ºé»˜è®¤å€¼
[filter setDefaults];
        
//è·å–ç»˜åˆ¶ä¸Šä¸‹æ–‡
CIContext *context = [CIContext contextWithOptions:nil];
        
//æ¸²æŸ“å¹¶è¾“å‡ºCIImage
CIImage *outputImage = [filter outputImage];
        
//åˆ›å»ºCGImageå¥æŸ„
CGImageRef cgImage = [context createCGImage:outputImage fromRect:[outputImage extent]];
        
//è·å–å›¾ç‰‡
UIImage *image = [UIImage imageWithCGImage:cgImage];
        
//é‡Šæ”¾CGImageå¥æŸ„
CGImageRelease(cgImage);
        
self.imageView.image = image;
```

### ç»¿å±æŠ åƒ

å¼•ç”¨å¤´æ–‡ä»¶ï¼š

```
#import "RSChromaKeyFilter.h"
```

å·¥å…·æ–¹æ³•ï¼š

```
RSChromaKeyFilter *filter=[[RSChromaKeyFilter alloc] initWithInputImage:self.greenImageView.image
                                                        backgroundImage:self.resultBgImageView.image];
    
self.resultImageView.image=[[UIImage imageWithCIImage:filter.outputImage] copy];
```

### é™æ€åˆæˆ

æ•ˆæœæ¼”ç¤ºï¼š

![](http://og1yl0w9z.bkt.clouddn.com/17-9-4/17807305.jpg) 

å¼•ç”¨å¤´æ–‡ä»¶ï¼š

```
#import <CoreImage/CoreImage.h>
#import "UIImageView+Gif.h"
```

æ ¸å¿ƒæ–¹æ³•ï¼š

```
// å›¾åƒè¯†åˆ«èƒ½åŠ›ï¼šå¯ä»¥åœ¨CIDetectorAccuracyHigh(è¾ƒå¼ºçš„å¤„ç†èƒ½åŠ›)ä¸CIDetectorAccuracyLow(è¾ƒå¼±çš„å¤„ç†èƒ½åŠ›)ä¸­é€‰æ‹©ï¼Œå› ä¸ºæƒ³è®©å‡†ç¡®åº¦é«˜ä¸€äº›åœ¨è¿™é‡Œé€‰æ‹©CIDetectorAccuracyHigh
NSDictionary *opts = [NSDictionary dictionaryWithObject:CIDetectorAccuracyHigh
                                                 forKey:CIDetectorAccuracy];

CIDetector *detector=[CIDetector detectorOfType:CIDetectorTypeFace context:nil options:opts];

//    CIDetector *detector = [CIDetector detectorOfType:CIDetectorTypeFace
//                                              context:nil
//                                              options:nil];

CIImage *image=[[CIImage alloc] initWithImage:self.oldImageView.image];
NSArray *faceArray = [detector featuresInImage:image
                                       options:nil];

/** å°† Core Image åæ ‡è½¬æ¢æˆ UIView åæ ‡ **/
//å¾—åˆ°å›¾ç‰‡çš„å°ºå¯¸
CGSize ciImageSize = [image extent].size;;
//å°†imageæ²¿yè½´å¯¹ç§°
CGAffineTransform transform = CGAffineTransformScale(CGAffineTransformIdentity, 1, -1);
//yè½´è´Ÿæ–¹å‘å¹³ç§»
transform = CGAffineTransformTranslate(transform,0,-ciImageSize.height);

for (CIFeature *f in faceArray){
    if ([f.type isEqualToString:CIFeatureTypeFace]) {
        CIFaceFeature *faceFeature=(CIFaceFeature *)f;
        // å®ç°åæ ‡è½¬æ¢
        CGSize viewSize = self.oldImageView.bounds.size;
        CGFloat scale = MIN(viewSize.width / ciImageSize.width,
                            viewSize.height / ciImageSize.height);
        CGFloat offsetX = (viewSize.width - ciImageSize.width * scale) / 2;
        CGFloat offsetY = (viewSize.height - ciImageSize.height * scale) / 2;
        // ç¼©æ”¾
        CGAffineTransform scaleTransform = CGAffineTransformMakeScale(scale, scale);
        //è·å–äººè„¸çš„frame
        CGRect faceViewBounds = CGRectApplyAffineTransform(faceFeature.bounds, transform);
        // ä¿®æ­£
        faceViewBounds = CGRectApplyAffineTransform(faceViewBounds,scaleTransform);
        faceViewBounds.origin.x += offsetX;
        faceViewBounds.origin.y += offsetY;
        
        UIView *faceView=[[UIView alloc] initWithFrame:faceViewBounds];
        faceView.layer.borderWidth=3;
        faceView.layer.borderColor=[UIColor orangeColor].CGColor;
        
        [self.oldImageView addSubview:faceView];
        
        /** åŠ å…‰ç¯  **/
        UIImageView *imageView=[UIImageView new];
        CGFloat haloWidth= faceViewBounds.size.width;
        CGFloat haloHeight= haloWidth * 159 / 351;
	       
	    ...
    }
    
}
```

### åŠ¨æ€åˆæˆ

æ•ˆæœæ¼”ç¤ºï¼š

![](http://og1yl0w9z.bkt.clouddn.com/17-9-4/28926041.jpg) 

å¼•ç”¨å¤´æ–‡ä»¶ï¼š

```
#import <GPUImage/GPUImage.h>
```

æ ¸å¿ƒæ–¹æ³•ï¼š
```
_faceThinking = YES;
CVPixelBufferRef pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer);
CFDictionaryRef attachments = CMCopyDictionaryOfAttachments(kCFAllocatorDefault, sampleBuffer, kCMAttachmentMode_ShouldPropagate);
CIImage *convertedImage = [[CIImage alloc] initWithCVPixelBuffer:pixelBuffer options:(__bridge NSDictionary *)attachments];

if (attachments)
    CFRelease(attachments);
NSDictionary *imageOptions = nil;
UIDeviceOrientation curDeviceOrientation = [[UIDevice currentDevice] orientation];
int exifOrientation;

enum {
    PHOTOS_EXIF_0ROW_TOP_0COL_LEFT			= 1, //   1  =  0th row is at the top, and 0th column is on the left (THE DEFAULT).
    PHOTOS_EXIF_0ROW_TOP_0COL_RIGHT			= 2, //   2  =  0th row is at the top, and 0th column is on the right.
    PHOTOS_EXIF_0ROW_BOTTOM_0COL_RIGHT      = 3, //   3  =  0th row is at the bottom, and 0th column is on the right.
    PHOTOS_EXIF_0ROW_BOTTOM_0COL_LEFT       = 4, //   4  =  0th row is at the bottom, and 0th column is on the left.
    PHOTOS_EXIF_0ROW_LEFT_0COL_TOP          = 5, //   5  =  0th row is on the left, and 0th column is the top.
    PHOTOS_EXIF_0ROW_RIGHT_0COL_TOP         = 6, //   6  =  0th row is on the right, and 0th column is the top.
    PHOTOS_EXIF_0ROW_RIGHT_0COL_BOTTOM      = 7, //   7  =  0th row is on the right, and 0th column is the bottom.
    PHOTOS_EXIF_0ROW_LEFT_0COL_BOTTOM       = 8  //   8  =  0th row is on the left, and 0th column is the bottom.
};
BOOL isUsingFrontFacingCamera = FALSE;
AVCaptureDevicePosition currentCameraPosition = [self.videoCamera cameraPosition];

...
```


## âš– åè®®

```
MIT License

Copyright (c) 2017 ReverseScale

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

## ğŸ˜¬  è”ç³»

* å¾®ä¿¡ : WhatsXie
* é‚®ä»¶ : ReverseScale@iCloud.com
* åšå®¢ : https://reversescale.github.io
